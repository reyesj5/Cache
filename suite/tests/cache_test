#!/usr/bin/env python
# coding=utf-8
import sys
import os.path
import time
import list_tests
import matrix_tests
import stack_tests
import threading
import subprocess
import inspect
from threading import Thread
import multiprocessing

args = sys.argv

def run_test(test, size = None, iterations = None):
	global running
	running = True
	# Measuring how long a script runs
	start = time.time()
	if size == None:
		if iterations == None:
			test()
		else:
			test(iterations)
	else:
		if iterations == None:
			test(size = size)
		else:
			test(iterations,size)
	print test.__name__, 'took', time.time()-start, 'seconds.'
	running = False
	return

def cache_info(architecture, cores, struct, test, size, iterations):
	directory = '../logs/'+ architecture + '/' + struct + '_cache/test_' + str(test)
	if not os.path.exists(directory):
		os.makedirs(directory)
	n = 1
	while os.path.exists('../logs/'+ architecture + '/' + struct + '_cache/test_' + str(test) + '/' + str(cores) + '_cores_'  + str(iterations) + '_' + str(size) + '_' + str(n) + '.log'):
		n += 1
	path = '../logs/'+ architecture + '/' + struct + '_cache/test_' + str(test) + '/' + str(cores) + '_cores_'  + str(iterations) + '_' + str(size) + '_' + str(n) + '.log'
	print ("Saving log at: " + path)
	log = open(path, 'a')  # so that data written to it will be appended
	log.flush()
	cache = subprocess.Popen(['date +"%Y-%m-%d %H:%M:%S:%3N"; lscpu | grep "cache"; echo'], stdout=log, stderr=log, shell=True)
	cache.wait()
	log.flush()
	time.sleep(1)
	while running:
		log.flush()
		command = 'date +"%Y-%m-%d %H:%M:%S:%3N"; timeout -s 2 --preserve-status 1s  perf stat -e cache-misses,cache-references,cpu-cycles,mem-loads,mem-stores,l1d.replacement,l1d_pend_miss.pending,l2_lines_in.all,l2_lines_out.useless_pref,l2_rqsts.all_code_rd,l2_rqsts.all_demand_miss,l2_rqsts.all_pf,l2_rqsts.rfo_hit,l2_rqsts.rfo_miss,longest_lat_cache.miss -p ' + str(os.getpid()) + '; cat /proc/meminfo | grep "Cached"; echo'
		#cache = subprocess.Popen(['date +"%Y-%m-%d %H:%M:%S:%3N"; lscpu | grep "cache"; cat /proc/meminfo | grep "Cached"; echo'], stdout=log, stderr=log, shell=True)
		cache = subprocess.Popen([command], stdout=log, stderr=log, shell=True)
		cache.wait()
		log.flush()
		time.sleep(10)
	log.close()
	return

# starts work at a core and keeps track of overall cores being used, size of structure, and # of iterations
def worker(architecture, cores, struct, test = None, size = None, iterations = None):
    #worker function
    if struct == 'matrices':
    	tests = matrix_tests.tests
    elif struct == 'lists':
    	tests = list_tests.tests
    elif struct == 'stack':
    	tests = stack_tests.tests
    else:
    	raise ValueError("Please choose a set of test(s) to run.")

    if test == None:
    	for i in range(len(tests)):
    		defaults =  inspect.getargspec(tests[i])[3]
    		if iterations == None:
    			n = defaults[0] / 100 # temp
    		else:
    			n = iterations
    		if size == None:
    			s = defaults[1]
    		else:
    			s = size
    		script = Thread(target = run_test, args = [tests[i],s,n])
    		cache = Thread(target = cache_info, args = [architecture, cores, struct, i+1,s,n])
    		script.start()
    		cache.start()
    		script.join()
    		cache.join()
    else:
    	defaults =  inspect.getargspec(tests[test-1])[3]
    	if iterations == None:
    		n = defaults[0] 
    	else:
    		n = iterations
    	if size == None:
    		s = defaults[1]
    	else:
    		s = size
    	script = Thread(target = run_test, args = [tests[test-1],size,iterations])
    	cache = Thread(target = cache_info, args = [architecture, cores, struct, test,s,n])
    	script.start()
    	cache.start()
    	script.join()
    	cache.join()

if __name__ == '__main__':
	if len(args) == 1:
		architecture = 'Zephyrus-M-GM501GS'
		cores = multiprocessing.cpu_count()
		struct = 'lists'
		test = None
		size = None
		iterations = None
	else:
		architecture = 'Zephyrus-M-GM501GS'
		cores = int(args[1])
		struct = args[2]
		test = None
		size = None
		iterations = None
	# Measuring how long a script runs
	start = time.time()
	# turning off watchdog to allow for cache flags
	cache = subprocess.Popen(['sudo sh -c "echo \'0\' > /proc/sys/kernel/nmi_watchdog"'], shell=True)
	cache.wait()
	time.sleep(1)
	jobs = []
	for i in range(cores):
		p = multiprocessing.Process(target=worker, args = (architecture, cores, struct, test, size, iterations))
		jobs.append(p)
		p.start()
	while True:
	    if any(process.is_alive() for process in jobs):
	        time.sleep(1)
	    else:
	    	# turning watchdog back on
	    	cache = subprocess.Popen(['sudo sh -c "echo \'1\' > /proc/sys/kernel/nmi_watchdog"'], shell=True)
	    	cache.wait()
	    	time.sleep(1)
	    	print('All processes done')
	    	print 'Script took', time.time()-start, 'seconds.'
	    	break